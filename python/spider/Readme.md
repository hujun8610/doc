#<center> Python网络爬虫
&emsp;&emsp;周末闲来无事，加上最近一直在看Python方面的书籍，想用python练练手。因此决定写一个小爬虫。从新浪微薄上爬点东西出来玩玩。
## 基本设计
### 目标
&emsp;&emsp;考虑到python的基础以及程序的健壮性，第一个版本的spider暂不考虑多线程的问题。首先使用单线程完成完整的功能开发及验证。爬取的结果以文件的形式的存储在本地（暂不考虑数据库）。爬取的网站为新浪微薄。
###基本功能
1. 根据提供的用户名和密码，支持新浪微博的登陆功能。
2. 解析返回的网页，提取其中大V的url地址，根据大V的url地址访问其网页获取其粉丝的基本信息。
3. 爬虫只考虑爬取两层网络，明星（第一层）及其相应的粉丝（第二层）。
4. 爬取过程中需要去重，即已经爬下来的信息不在重新爬取。
5. 需要处理爬取、解析网页过程中遇到的各种异常信息。
6. 为了防止url被封，设定爬取间隔，或者考虑使用网络代理。

### 基本流程
1. 使用用户名和密码登陆微博（种子用户）。
2. 解析网页，提取大V的url地址。
3. 根据获取的url地址，访问网页，提取大V的粉丝的基本信息。在此过程中需要一边去重一边解析。
 - 基本信息包含，用户名、年龄、性别、微博等级、关注的个数、粉丝的个数以及其发布微博的条数。
4. 将获取的相关基本信息写入本地文件。
5. 处理网页下载、解析过程中出现的各种异常信息，确保程序能够持续的爬取网页。

### 模块划分
&emsp;&emsp;整体结构分为三层：
1. 网络层：登陆新浪微薄，根据url信息返回网页。
2. 中间层：解析返回的网页，爬取去重，提取粉丝的基本信息。
3. 存储：将提取的基本信息写入文件。





